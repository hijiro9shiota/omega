# Omega Study Platform

Omega Study est une plateforme acad√©mique qui combine une prise de notes vocale locale et des fonctionnalit√©s IA √† la demande pour r√©sumer, questionner et ludifier les cours. L'objectif est de limiter l'usage payant d'API en stockant uniquement le texte transcrit et en n'appelant l'IA que lorsque l'utilisateur le demande.

## Aper√ßu des fonctionnalit√©s

- **Capture vocale c√¥t√© navigateur** gr√¢ce √† l'API Web Speech, sans stockage de fichiers audio volumineux.

- **√âditeur de notes en temps r√©el** avec statistiques, tags contextuels et sauvegarde locale automatique.
- **Outils IA √† la carte** : r√©sum√©, quiz, r√©ponses aux questions et mini-jeux p√©dagogiques. Chaque outil ne contacte le backend qu'√† la demande et met en cache ses r√©ponses pour √©conomiser les cr√©dits IA.
- **Fallback local intelligent** lorsque le serveur IA est indisponible : r√©sum√©s simplifi√©s, quiz g√©n√©r√©s via heuristiques et conseils d'auto-r√©vision.
- **Exports instantan√©s** en Markdown ou JSON pour partager vos notes.

- **√âditeur de notes en temps r√©el** avec statistiques de mots et synchronisation avec la transcription.
- **Sauvegarde c√¥t√© serveur** (Node.js/Express) dans un fichier JSON l√©ger pour √©viter une base de donn√©es co√ªteuse.
- **Outils IA √† la carte** : r√©sum√©, quiz, r√©ponses aux questions et mini-jeux p√©dagogiques.
- **Strat√©gies d'optimisation des co√ªts** :
  - R√©sum√©s et quiz locaux (fallback) lorsque la cl√© OpenAI est absente ou que le texte est court.
  - Mise en cache des r√©ponses IA sur le serveur pour √©viter des appels redondants.
  - Possibilit√© de chunker les transcripts avant envoi √† l'IA pour contr√¥ler la consommation de tokens.


## Structure du projet

```
backend/   ‚Üí API Express, stockage des sessions, int√©gration OpenAI optionnelle
frontend/  ‚Üí Interface HTML/CSS/JS autonome (aucune √©tape de build n√©cessaire)
```

## Utilisation de l'interface

1. Ouvrez simplement `frontend/index.html` dans votre navigateur (double-clic ou ¬´ Ouvrir avec Live Server ¬ª). Aucun bundler n'est requis.
2. Cliquez sur ¬´ Commencer l'enregistrement ¬ª pour d√©clencher la reconnaissance vocale (Chrome recommand√©). Les notes sont nettoy√©es en direct et enrichies de suggestions d'actions.
3. Utilisez les boutons de la section ¬´ Analyse IA √† la demande ¬ª pour g√©n√©rer r√©sum√©, quiz, r√©ponses et jeux. En l'absence de backend, une version locale vous est propos√©e pour continuer √† travailler sans attendre.
4. Ajoutez des tags contextuels, suivez les statistiques automatiques et exportez vos notes en Markdown ou JSON.

> üí° L'autosauvegarde locale conserve votre travail m√™me en cas de fermeture d'onglet.

## Configuration du backend (optionnelle)

Le backend Express reste disponible pour stocker les sessions et d√©l√©guer les analyses IA compl√®tes.

1. Installez les d√©pendances c√¥t√© backend :

   ```bash
   cd backend
   npm install
   ```

   > Si le registre npm est restreint dans votre environnement, configurez `npm config set registry https://registry.npmjs.org/` ou un miroir autoris√©.

2. Cr√©ez le fichier `.env` depuis l'exemple et ajoutez votre cl√© OpenAI :

   ```bash
   cp .env.example .env
   # puis √©ditez .env pour y placer OPENAI_API_KEY=...
   ```

3. Lancez le serveur :

   ```bash
   npm run dev
   ```

4. Les appels IA resteront facultatifs : sans cl√©, le serveur emploie des algorithmes locaux pour fournir des r√©sultats basiques. L'interface d√©tecte automatiquement la pr√©sence du backend et profite de la mise en cache c√¥t√© serveur.

## D√©ploiement

- **Frontend** : il s'agit d'un bundle statique. Publiez simplement le dossier `frontend/` (ou son contenu) sur un h√©bergement statique, un CDN ou m√™me un dossier partag√©.
- **Backend** : d√©ployez `backend/` sur la plateforme de votre choix (Railway, Render, Fly.io, VPS‚Ä¶) en veillant √† configurer `OPENAI_API_KEY` et un stockage persistant pour `backend/data/sessions.json`.

## Notes sur la confidentialit√©

- Les enregistrements vocaux ne quittent jamais le navigateur : seul le texte transcrit est stock√©.
- Les appels IA ne sont d√©clench√©s qu'√† la demande explicite de l'utilisateur et profitent d'une mise en cache pour limiter la facture.
frontend/  ‚Üí Interface Vite + React
```

## Pr√©-requis

- Node.js 18+
- (Optionnel) Une cl√© API OpenAI disponible dans `backend/.env`

## Installation

```bash
# Installer les d√©pendances c√¥t√© backend
cd backend
npm install

# Installer les d√©pendances c√¥t√© frontend
cd ../frontend
npm install
```

> üí° Si le registre npm est restreint dans votre environnement, configurez `npm config set registry https://registry.npmjs.org/` ou un miroir autoris√©.

## Configuration

1. Copier le fichier d'exemple et renseigner la cl√© API si vous souhaitez activer l'IA OpenAI.

```bash
cd backend
cp .env.example .env
# puis √©diter .env pour y placer OPENAI_API_KEY=...
```

2. Les appels IA restent facultatifs : sans cl√©, le serveur emploie des algorithmes locaux pour fournir des r√©sultats basiques.

## Lancer les services

Dans deux terminaux s√©par√©s :

```bash
# Terminal 1 - backend
cd backend
npm run dev

# Terminal 2 - frontend
cd frontend
npm run dev
```

Le frontend est accessible sur http://localhost:5173 et proxe automatiquement les requ√™tes `/api` vers l'API Express sur http://localhost:4000.

## Tests et qualit√©

- `npm run lint` dans `backend/` v√©rifie le style de code serveur.
- Un linter React peut √™tre ajout√© c√¥t√© frontend selon vos pr√©f√©rences.

## D√©ploiement

Pour un d√©ploiement l√©ger :

1. Construire le frontend :

```bash
cd frontend
npm run build
```

2. Servir le dossier g√©n√©r√© `frontend/dist` via un CDN ou un serveur statique (ex. Nginx).
3. H√©berger le backend (Railway, Render, Fly.io, VPS) en veillant √† configurer `OPENAI_API_KEY` et un stockage persistant pour `backend/data/sessions.json`.

## Notes sur la confidentialit√©

- Les enregistrements vocaux ne quittent jamais le navigateur : seul le texte transcrit est transmis au serveur.
- Les appels IA ne sont d√©clench√©s qu'√† la demande explicite de l'utilisateur.


Bon apprentissage avec Omega Study !
